{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def findPrime(x):\n",
    "    prime=[2, 3] #\n",
    "    notPrime=[]\n",
    "    numbers=[2,3]\n",
    "    exclude=4 #done to exclude 0 and 1 as they are unique numbers, exclude 2 and 3 as to get the list started.\n",
    "    for i in range(x-exclude+1):\n",
    "        num=i+exclude\n",
    "        status=True\n",
    "        \n",
    "        for j in prime:\n",
    "            if num%j==0:\n",
    "                status=False\n",
    "        numbers.append(num)\n",
    "        if status:\n",
    "            prime.append(num)\n",
    "        else:\n",
    "            notPrime.append(num)\n",
    "    return(prime, notPrime, numbers)\n",
    "\n",
    "number=10000\n",
    "prime, notPrime,numbers=findPrime(number)\n",
    "#print(prime, notPrime)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " ..., \n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "label=np.zeros((number-1,1))\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " ..., \n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " ..., \n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]]\n"
     ]
    }
   ],
   "source": [
    "for i in prime:\n",
    "    label[i-2]=1\n",
    "#print(label)\n",
    "\n",
    "from keras.utils import np_utils\n",
    "label_final = np_utils.to_categorical(np.array(label), 2)\n",
    "print(label)\n",
    "print(label_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.  0.  0.  0.  2.]]\n",
      "\n",
      " [[ 0.  0.  0.  0.  3.]]\n",
      "\n",
      " [[ 0.  0.  0.  0.  4.]]\n",
      "\n",
      " ..., \n",
      " [[ 0.  9.  9.  9.  8.]]\n",
      "\n",
      " [[ 0.  9.  9.  9.  9.]]\n",
      "\n",
      " [[ 1.  0.  0.  0.  0.]]]\n"
     ]
    }
   ],
   "source": [
    "data=np.zeros((number-1,1,len(str(number))))\n",
    "for i in range(number-1):\n",
    "    num=i+2\n",
    "    for k in range(len(str(num))):\n",
    "        data[i][0][len(str(number))-k-1]=int(str(num)[len(str(num))-k-1])\n",
    "#print(data)\n",
    "#data_final = np_utils.to_categorical(np.array(data), number+1)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, label_final, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7999, 1, 5)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_25 (Conv1D)           (None, 1, 256)            6656      \n",
      "_________________________________________________________________\n",
      "conv1d_26 (Conv1D)           (None, 1, 512)            262656    \n",
      "_________________________________________________________________\n",
      "conv1d_27 (Conv1D)           (None, 1, 1024)           525312    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 1, 1024)           0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 2)                 2050      \n",
      "=================================================================\n",
      "Total params: 796,674.0\n",
      "Trainable params: 796,674.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#neural network(s):\n",
    "from keras.layers import Conv1D, MaxPooling1D, GlobalAveragePooling1D, AveragePooling1D\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.models import Sequential\n",
    "\n",
    "print(X_train.shape)\n",
    "\n",
    "Prime_model = Sequential()\n",
    "Prime_model.add(Conv1D(filters=256, kernel_size=5, padding='same', activation='relu', input_shape=(X_train.shape[1],X_train.shape[2])))\n",
    "#Prime_model.add(MaxPooling1D(pool_size=2))\n",
    "Prime_model.add(Conv1D(filters=512, kernel_size=2, padding='same', activation='relu'))\n",
    "#Prime_model.add(MaxPooling1D(pool_size=2))\n",
    "Prime_model.add(Conv1D(filters=1024, kernel_size=1, padding='same', activation='relu'))\n",
    "#Prime_model.add(MaxPooling1D(pool_size=4))\n",
    "#Prime_model.add(AveragePooling1D(pool_size=(2, 2), strides=None, padding='valid'))\n",
    "Prime_model.add(Dropout(.3))\n",
    "Prime_model.add(Flatten())\n",
    "Prime_model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "Prime_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#compile network:\n",
    "Prime_model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7999 samples, validate on 2000 samples\n",
      "Epoch 1/15\n",
      "7987/7999 [============================>.] - ETA: 0s - loss: 0.3943 - acc: 0.8772Epoch 00000: val_loss improved from inf to 0.41614, saving model to D:\\Machine Learning\\LearningPrime/weights.best.from_scratch.hdf5\n",
      "7999/7999 [==============================] - 51s - loss: 0.3938 - acc: 0.8774 - val_loss: 0.4161 - val_acc: 0.8740\n",
      "Epoch 2/15\n",
      "7987/7999 [============================>.] - ETA: 0s - loss: 0.3785 - acc: 0.8778Epoch 00001: val_loss improved from 0.41614 to 0.36660, saving model to D:\\Machine Learning\\LearningPrime/weights.best.from_scratch.hdf5\n",
      "7999/7999 [==============================] - 58s - loss: 0.3784 - acc: 0.8779 - val_loss: 0.3666 - val_acc: 0.8740\n",
      "Epoch 3/15\n",
      "7994/7999 [============================>.] - ETA: 0s - loss: 0.3746 - acc: 0.8778Epoch 00002: val_loss did not improve\n",
      "7999/7999 [==============================] - 58s - loss: 0.3745 - acc: 0.8779 - val_loss: 0.3668 - val_acc: 0.8740\n",
      "Epoch 4/15\n",
      "7994/7999 [============================>.] - ETA: 0s - loss: 0.3767 - acc: 0.8779Epoch 00003: val_loss improved from 0.36660 to 0.36225, saving model to D:\\Machine Learning\\LearningPrime/weights.best.from_scratch.hdf5\n",
      "7999/7999 [==============================] - 59s - loss: 0.3767 - acc: 0.8779 - val_loss: 0.3623 - val_acc: 0.8740\n",
      "Epoch 5/15\n",
      "7994/7999 [============================>.] - ETA: 0s - loss: 0.3752 - acc: 0.8780Epoch 00004: val_loss did not improve\n",
      "7999/7999 [==============================] - 61s - loss: 0.3757 - acc: 0.8779 - val_loss: 0.3669 - val_acc: 0.8740\n",
      "Epoch 6/15\n",
      "7987/7999 [============================>.] - ETA: 0s - loss: 0.3855 - acc: 0.8778Epoch 00005: val_loss did not improve\n",
      "7999/7999 [==============================] - 64s - loss: 0.3853 - acc: 0.8779 - val_loss: 0.3644 - val_acc: 0.8740\n",
      "Epoch 7/15\n",
      "7994/7999 [============================>.] - ETA: 0s - loss: 0.3621 - acc: 0.8778Epoch 00006: val_loss did not improve\n",
      "7999/7999 [==============================] - 65s - loss: 0.3619 - acc: 0.8779 - val_loss: 0.3634 - val_acc: 0.8740\n",
      "Epoch 8/15\n",
      "7987/7999 [============================>.] - ETA: 0s - loss: 0.3618 - acc: 0.8779Epoch 00007: val_loss did not improve\n",
      "7999/7999 [==============================] - 64s - loss: 0.3619 - acc: 0.8779 - val_loss: 0.3660 - val_acc: 0.8740\n",
      "Epoch 9/15\n",
      "7994/7999 [============================>.] - ETA: 0s - loss: 0.3587 - acc: 0.8778Epoch 00008: val_loss did not improve\n",
      "7999/7999 [==============================] - 64s - loss: 0.3586 - acc: 0.8779 - val_loss: 0.3628 - val_acc: 0.8740\n",
      "Epoch 10/15\n",
      "7994/7999 [============================>.] - ETA: 0s - loss: 0.3600 - acc: 0.8778Epoch 00009: val_loss improved from 0.36225 to 0.35972, saving model to D:\\Machine Learning\\LearningPrime/weights.best.from_scratch.hdf5\n",
      "7999/7999 [==============================] - 65s - loss: 0.3599 - acc: 0.8779 - val_loss: 0.3597 - val_acc: 0.8740\n",
      "Epoch 11/15\n",
      "7994/7999 [============================>.] - ETA: 0s - loss: 0.3559 - acc: 0.8778Epoch 00010: val_loss improved from 0.35972 to 0.35806, saving model to D:\\Machine Learning\\LearningPrime/weights.best.from_scratch.hdf5\n",
      "7999/7999 [==============================] - 65s - loss: 0.3558 - acc: 0.8779 - val_loss: 0.3581 - val_acc: 0.8740\n",
      "Epoch 12/15\n",
      "7994/7999 [============================>.] - ETA: 0s - loss: 0.3558 - acc: 0.8778Epoch 00011: val_loss did not improve\n",
      "7999/7999 [==============================] - 64s - loss: 0.3556 - acc: 0.8779 - val_loss: 0.3752 - val_acc: 0.8740\n",
      "Epoch 13/15\n",
      "7994/7999 [============================>.] - ETA: 0s - loss: 0.3586 - acc: 0.8778Epoch 00012: val_loss did not improve\n",
      "7999/7999 [==============================] - 64s - loss: 0.3585 - acc: 0.8779 - val_loss: 0.3692 - val_acc: 0.8740\n",
      "Epoch 14/15\n",
      "7994/7999 [============================>.] - ETA: 0s - loss: 0.3550 - acc: 0.8783Epoch 00013: val_loss did not improve\n",
      "7999/7999 [==============================] - 65s - loss: 0.3556 - acc: 0.8779 - val_loss: 0.3611 - val_acc: 0.8740\n",
      "Epoch 15/15\n",
      "7994/7999 [============================>.] - ETA: 0s - loss: 0.3535 - acc: 0.8778Epoch 00014: val_loss did not improve\n",
      "7999/7999 [==============================] - 64s - loss: 0.3534 - acc: 0.8779 - val_loss: 0.3609 - val_acc: 0.8740\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x16dc4f28>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#running network:\n",
    "from keras.callbacks import ModelCheckpoint  \n",
    "\n",
    "### TODO: specify the number of epochs that you would like to use to train the model.\n",
    "\n",
    "epochs = 15\n",
    "\n",
    "### Do NOT modify the code below this line.\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='D:\\Machine Learning\\LearningPrime/weights.best.from_scratch.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "Prime_model.fit(X_train, y_train, \n",
    "          validation_data=(X_test, y_test),\n",
    "          epochs=epochs, batch_size=7, callbacks=[checkpointer], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#prediction:\n",
    "#load model\n",
    "Prime_model.load_weights('D:\\Machine Learning\\LearningPrime/weights.best.from_scratch.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0.  1.  0.]]\n"
     ]
    }
   ],
   "source": [
    "def num(x, number):\n",
    "    zeros=np.zeros(len(str(number)))\n",
    "    for k in range((len(str(x)))):\n",
    "        zeros[len(str(number))-k-1]=int(str(x)[len(str(x))-k-1])\n",
    "    return(np.array([zeros]))\n",
    "\n",
    "\n",
    "print(num(10, number))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def predPrime(x):\n",
    "    #Prime_model.predict(np.array([num(x, number)]))\n",
    "    #print(Prime_model.predict(np.array([num(x, number)]))[0])\n",
    "    return(Prime_model.predict(np.array([num(x, number)]))[0][0],Prime_model.predict(np.array([num(x, number)]))[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i= 2   probNotPrime= 0.819416   probPrime= 0.180584\n",
      "i= 3   probNotPrime= 0.845458   probPrime= 0.154542\n",
      "i= 5   probNotPrime= 0.861089   probPrime= 0.138911\n",
      "i= 7   probNotPrime= 0.861089   probPrime= 0.138911\n",
      "i= 11   probNotPrime= 0.785131   probPrime= 0.214869\n",
      "i= 13   probNotPrime= 0.850336   probPrime= 0.149664\n",
      "i= 17   probNotPrime= 0.861089   probPrime= 0.138911\n",
      "i= 19   probNotPrime= 0.861089   probPrime= 0.138911\n",
      "i= 23   probNotPrime= 0.854452   probPrime= 0.145548\n",
      "i= 29   probNotPrime= 0.861089   probPrime= 0.138911\n",
      "i= 31   probNotPrime= 0.774074   probPrime= 0.225926\n",
      "i= 37   probNotPrime= 0.861089   probPrime= 0.138911\n",
      "i= 41   probNotPrime= 0.759308   probPrime= 0.240692\n",
      "i= 43   probNotPrime= 0.851214   probPrime= 0.148786\n",
      "i= 47   probNotPrime= 0.861089   probPrime= 0.138911\n",
      "i= 53   probNotPrime= 0.847792   probPrime= 0.152208\n",
      "i= 59   probNotPrime= 0.861089   probPrime= 0.138911\n",
      "i= 61   probNotPrime= 0.729192   probPrime= 0.270808\n",
      "i= 67   probNotPrime= 0.861089   probPrime= 0.138911\n",
      "i= 71   probNotPrime= 0.715315   probPrime= 0.284685\n",
      "i= 9811   probNotPrime= 0.830036   probPrime= 0.169964\n",
      "i= 9817   probNotPrime= 0.887764   probPrime= 0.112236\n",
      "i= 9829   probNotPrime= 0.881159   probPrime= 0.118841\n",
      "i= 9833   probNotPrime= 0.916447   probPrime= 0.0835528\n",
      "i= 9839   probNotPrime= 0.883833   probPrime= 0.116167\n",
      "i= 9851   probNotPrime= 0.802708   probPrime= 0.197292\n",
      "i= 9857   probNotPrime= 0.90823   probPrime= 0.0917697\n",
      "i= 9859   probNotPrime= 0.893499   probPrime= 0.106501\n",
      "i= 9871   probNotPrime= 0.789131   probPrime= 0.210869\n",
      "i= 9883   probNotPrime= 0.923556   probPrime= 0.0764436\n",
      "i= 9887   probNotPrime= 0.921321   probPrime= 0.0786791\n",
      "i= 9901   probNotPrime= 0.841784   probPrime= 0.158216\n",
      "i= 9907   probNotPrime= 0.885167   probPrime= 0.114833\n",
      "i= 9923   probNotPrime= 0.918146   probPrime= 0.0818542\n",
      "i= 9929   probNotPrime= 0.882839   probPrime= 0.117161\n",
      "i= 9931   probNotPrime= 0.821977   probPrime= 0.178023\n",
      "i= 9941   probNotPrime= 0.815163   probPrime= 0.184837\n",
      "i= 9949   probNotPrime= 0.890515   probPrime= 0.109485\n",
      "i= 9967   probNotPrime= 0.91477   probPrime= 0.0852295\n",
      "i= 9973   probNotPrime= 0.925137   probPrime= 0.074863\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    probNotPrime, probPrime= predPrime(prime[i])\n",
    "    print('i=', prime[i], '  probNotPrime=', probNotPrime, '  probPrime=', probPrime)\n",
    "\n",
    "for i in range(20):\n",
    "    probNotPrime, probPrime= predPrime(prime[len(prime)-20+i])\n",
    "    print('i=', prime[len(prime)-20+i], '  probNotPrime=', probNotPrime, '  probPrime=', probPrime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i= 4   probNotPrime= 0.861089   probPrime= 0.138911\n",
      "i= 6   probNotPrime= 0.861089   probPrime= 0.138911\n",
      "i= 8   probNotPrime= 0.861089   probPrime= 0.138911\n",
      "i= 9   probNotPrime= 0.861089   probPrime= 0.138911\n",
      "i= 10   probNotPrime= 1.0   probPrime= 1.22442e-12\n",
      "i= 12   probNotPrime= 0.826661   probPrime= 0.173339\n",
      "i= 14   probNotPrime= 0.861089   probPrime= 0.138911\n",
      "i= 15   probNotPrime= 0.861089   probPrime= 0.138911\n",
      "i= 16   probNotPrime= 0.861089   probPrime= 0.138911\n",
      "i= 18   probNotPrime= 0.861089   probPrime= 0.138911\n",
      "i= 20   probNotPrime= 1.0   probPrime= 1.26332e-12\n",
      "i= 21   probNotPrime= 0.779344   probPrime= 0.220656\n",
      "i= 22   probNotPrime= 0.826933   probPrime= 0.173067\n",
      "i= 24   probNotPrime= 0.861089   probPrime= 0.138911\n",
      "i= 25   probNotPrime= 0.861089   probPrime= 0.138911\n",
      "i= 26   probNotPrime= 0.861089   probPrime= 0.138911\n",
      "i= 27   probNotPrime= 0.861089   probPrime= 0.138911\n",
      "i= 28   probNotPrime= 0.861089   probPrime= 0.138911\n",
      "i= 30   probNotPrime= 1.0   probPrime= 5.70978e-13\n",
      "i= 32   probNotPrime= 0.823723   probPrime= 0.176277\n",
      "i= 9981   probNotPrime= 0.788471   probPrime= 0.211529\n",
      "i= 9982   probNotPrime= 0.880169   probPrime= 0.119831\n",
      "i= 9983   probNotPrime= 0.926464   probPrime= 0.0735361\n",
      "i= 9984   probNotPrime= 0.938154   probPrime= 0.0618458\n",
      "i= 9985   probNotPrime= 0.934074   probPrime= 0.065926\n",
      "i= 9986   probNotPrime= 0.928792   probPrime= 0.0712081\n",
      "i= 9987   probNotPrime= 0.923121   probPrime= 0.0768786\n",
      "i= 9988   probNotPrime= 0.91704   probPrime= 0.0829601\n",
      "i= 9989   probNotPrime= 0.91053   probPrime= 0.0894703\n",
      "i= 9990   probNotPrime= 1.0   probPrime= 2.55086e-13\n",
      "i= 9991   probNotPrime= 0.782235   probPrime= 0.217765\n",
      "i= 9992   probNotPrime= 0.874942   probPrime= 0.125058\n",
      "i= 9993   probNotPrime= 0.927769   probPrime= 0.0722308\n",
      "i= 9994   probNotPrime= 0.939274   probPrime= 0.0607262\n",
      "i= 9995   probNotPrime= 0.937447   probPrime= 0.0625535\n",
      "i= 9996   probNotPrime= 0.932415   probPrime= 0.067585\n",
      "i= 9997   probNotPrime= 0.92701   probPrime= 0.0729896\n",
      "i= 9998   probNotPrime= 0.92121   probPrime= 0.07879\n",
      "i= 9999   probNotPrime= 0.914992   probPrime= 0.0850075\n",
      "i= 10000   probNotPrime= 1.0   probPrime= 1.92549e-13\n"
     ]
    }
   ],
   "source": [
    "#for i in notPrime:\n",
    "#    probNotPrime, probPrime= predPrime(i)\n",
    "#    print('i=', i, '  probNotPrime=', probNotPrime, '  probPrime=', probPrime)\n",
    "    \n",
    "    \n",
    "for i in range(20):\n",
    "    probNotPrime, probPrime= predPrime(notPrime[i])\n",
    "    print('i=', notPrime[i], '  probNotPrime=', probNotPrime, '  probPrime=', probPrime)\n",
    "\n",
    "for i in range(20):\n",
    "    probNotPrime, probPrime= predPrime(notPrime[len(notPrime)-20+i])\n",
    "    print('i=', notPrime[len(notPrime)-20+i], '  probNotPrime=', probNotPrime, '  probPrime=', probPrime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#data1D=[]\n",
    "notPrimeArray=[]\n",
    "\n",
    "for i in numbers:\n",
    "    #data1D.append(int(i[0]))\n",
    "    #print (i)\n",
    "    #print (int(i[0]))\n",
    "    #print (2)\n",
    "    #probNotPrime, probPrime=predPrime(int(i[0]))\n",
    "    probNotPrime, probPrime=predPrime(i)\n",
    "    notPrimeArray.append(probNotPrime)\n",
    "    \n",
    "\n",
    "#print(numbers)\n",
    "#print(notPrimeArray)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7999 7999\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
       "          learning_rate=1.0, n_estimators=50, random_state=None)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "labelArray=[]\n",
    "for i in label:\n",
    "    #print (i[0])\n",
    "    labelArray.append(i[0])\n",
    "\n",
    "notPrimeArray2D=[] \n",
    "for i in notPrimeArray:\n",
    "    notPrimeArray2D.append([i])\n",
    "    \n",
    "#print (labelArray[0])    \n",
    "\n",
    "X_train_boost, X_test_boost, y_train_boost, y_test_boost = train_test_split(notPrimeArray2D, labelArray, test_size=0.2, random_state=42)\n",
    "\n",
    "clf=AdaBoostClassifier(n_estimators=50)\n",
    "\n",
    "print (len(X_train_boost), len(y_train_boost))\n",
    "\n",
    "#print (X_train_boost)\n",
    "#print (y_train_boost)\n",
    "\n",
    "clf.fit(X_train_boost, y_train_boost)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def boostpredict(x):\n",
    "    return(clf.predict(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.004882017900732303\n"
     ]
    }
   ],
   "source": [
    "accuracyPrime=0\n",
    "for i in prime:\n",
    "    probNotPrime, probPrime= predPrime(i)\n",
    "    #print('i=', i, '  probNotPrime=', probNotPrime, '  probPrime=', probPrime)\n",
    "    result=boostpredict(probNotPrime)\n",
    "    #print('i=', i, '  probNotPrime=', result)\n",
    "    if result==[1.]:\n",
    "        accuracyPrime+=1\n",
    "\n",
    "print(accuracyPrime/len(prime))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.999429874572406\n"
     ]
    }
   ],
   "source": [
    "#for i in notPrime:\n",
    "#    probNotPrime, probPrime= predPrime(i)\n",
    "#    #print('i=', i, '  probNotPrime=', probNotPrime, '  probPrime=', probPrime)\n",
    "#    print('i=', i, '  probNotPrime=', boostpredict(probNotPrime))\n",
    "    \n",
    "    \n",
    "accuracyNotPrime=0\n",
    "for i in notPrime:\n",
    "    probNotPrime, probPrime= predPrime(i)\n",
    "    #print('i=', i, '  probNotPrime=', probNotPrime, '  probPrime=', probPrime)\n",
    "    result=boostpredict(probNotPrime)\n",
    "    #print('i=', i, '  probNotPrime=', result)\n",
    "    if result==[0.]:\n",
    "        accuracyNotPrime+=1\n",
    "\n",
    "print(accuracyNotPrime/len(notPrime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 2, [3, 4]], [5, 6], 7]\n",
      "[1, 2, [3, 4]]\n",
      "[3, 4]\n",
      "[5, 6]\n",
      "[1, 2, 3, 4, 5, 6, 7]\n"
     ]
    }
   ],
   "source": [
    "def flatten_list(a, result=None):\n",
    "    \"\"\"Flattens a nested list.\n",
    "\n",
    "        >>> flatten_list([ [1, 2, [3, 4] ], [5, 6], 7])\n",
    "        [1, 2, 3, 4, 5, 6, 7]\n",
    "    \"\"\"\n",
    "    print(a)\n",
    "    if result is None:\n",
    "        result = []\n",
    "\n",
    "    for x in a:\n",
    "        if isinstance(x, list):\n",
    "            flatten_list(x, result)\n",
    "        else:\n",
    "            result.append(x)\n",
    "\n",
    "    return result\n",
    "\n",
    "a=[ [1, 2, [3, 4] ], [5, 6], 7]\n",
    "print(flatten_list(a, result=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  1.  0. ...,  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "print (np.array([num(1, number)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  2.00000000e+00]\n",
      " [  3.00000000e+00]\n",
      " [  4.00000000e+00]\n",
      " ..., \n",
      " [  4.99800000e+03]\n",
      " [  4.99900000e+03]\n",
      " [  5.00000000e+03]]\n",
      "(0.84858251, 0.15141749)\n",
      "8.4858250618\n",
      "a= 8\n",
      "b= 4\n",
      "c= 8\n",
      "d= 5\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(data)\n",
    "print (predPrime(2))\n",
    "probNotPrime, probPrime= predPrime(2)\n",
    "\n",
    "print (probNotPrime*10)\n",
    "a= (math.floor(probNotPrime*10))\n",
    "b=math.floor(probNotPrime*100-a*10)\n",
    "c=math.floor(probNotPrime*1000-(a*100+b*10))\n",
    "d=math.floor(probNotPrime*10000-(a*1000+b*100+c*10))\n",
    "e=math.floor(probNotPrime*100000-d*10)\n",
    "f=math.floor(probNotPrime*1000000-e*10)\n",
    "g=math.floor(probNotPrime*10000000-f*10)\n",
    "h=math.floor(probNotPrime*100000000-g*10)\n",
    "i=math.floor(probNotPrime*1000000000-h*10)\n",
    "j=math.floor(probNotPrime*10000000000-i*10)\n",
    "\n",
    "print ('a=', a)\n",
    "print ('b=', b)\n",
    "print ('c=', c)\n",
    "print ('d=', d)\n",
    "#print ('e=', e)\n",
    "\n",
    "#print ('f=', f)\n",
    "#print ('g=', g)\n",
    "#print ('h=', h)\n",
    "#print ('i=', i)\n",
    "#print ('j=', j)\n",
    "\n",
    "def digits(x,y):\n",
    "    result=([math.floor(x*10)])\n",
    "    if y>0:\n",
    "        return(result.append(digits(x*10-math.floor(x*10),y-1)))\n",
    "    else:\n",
    "        return(result)\n",
    "    \n",
    "print (digits(probNotPrime, 1))\n",
    "#    \n",
    "#def digitsVect(x):\n",
    "\n",
    "#for i in data:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:icebergChallenge]",
   "language": "python",
   "name": "conda-env-icebergChallenge-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
